# How to run

Convert the `FER2013.csv` file into `.jpg` images. This can be achieved by running the script `convert_fer2013csv_to_images.py`. It will put the images in a folder called images and generate the file `labels.npy` with the emotion for each image.

Given a set of `.jpg` images use [Openface](https://github.com/TadasBaltrusaitis/OpenFace) to get the AUs.

This can be achieved by running the following commands:

Get name of docker container:

`docker ps`

Copy images to docker Openface

`docker cp <folder_to_copy>  <docker_container_name>:/opt/OpenFace/build/bin/images`

Run OpenFace to get the AUs. Docker will generate an output text file for each image it was able to process. The path names must be absolute.

`./FaceLandmarkImg -fdir /path_to_images -ofir /path_to_output_directory`

Copy the AUs generated by docker into a folder named `fer2013_AU`

Use `parse.py` to extract the AU intensities and occurences from the docker output files and save this data in `.npy` files

`python parse.py`

You should see now the output files: `intens_fer.npy` and `occur_fer.npy`.

Use train.py to train the model and predict

To train

`python train.py --train=yes`

To predict put images in a folder named `predict_images` and their AUs in a folder named `predict_images_AU` and then run:

`python train.py -e=yes`

If a set of labels is available for this images then it is possible to run the command:

`python train.py -e=yes -labels=labels.npy`

where `labels.npy` is a numpy array that contains the labels of the images. 